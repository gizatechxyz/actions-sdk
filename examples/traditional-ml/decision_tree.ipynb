{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional ML Models for ZKML: Decision Tree\n",
    "\n",
    "*In this series of tutorials, we delve into the world of traditional machine learning models for ZKML. Despite the hype surrounding advanced AI techniques, traditional ML models often offer superior performance or sufficiently robust results for specific applications. This is particularly true for ZKML use cases, where computational proof costs can be a critical factor. We aim to equip you with guides on how to implement machine learning algorithms suitable for Giza platform applications. This includes practical steps for converting your scikit-learn models to the ONNX format, transpiling them to Orion Cairo, and deploying inference endpoints for prediction in AI Action.*\n",
    "\n",
    "In this tutorial, you will learn how to use the Giza tools through a Decision Tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Starting\n",
    "Before we start, ensure that you have installed the Giza stack, created a user, and logged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! pipx install giza-cli # Install the Giza-CLI\n",
    "! pip install giza-agents\n",
    "\n",
    "! giza users create # Create a user\n",
    "! giza users login # Login to your account\n",
    "! giza users create-api-key # Create an API key. We recommend you do this so you don't have to reconnect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train a Decision Tree Model\n",
    "We'll start by creating a simple decision tree model using Scikit-Learn and train it on the iris dataset. We will then use the [Hummingbirds](https://github.com/microsoft/hummingbird) library to convert the model to torch graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier as De\n",
    "from hummingbird.ml import convert\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X = X.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "clr = De()\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "model = convert(clr, \"torch\", X_test[:1]).model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Model to ONNX Format\n",
    "Giza only supports ONNX models so you'll need to convert the model to ONNX format. This can be done post training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "\n",
    "input_sample = torch.from_numpy(X_test[:1])\n",
    "\n",
    "# Specify the path to save the ONNX model\n",
    "onnx_model_path = \"decision_tree.onnx\"\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,\n",
    "                  input_sample,\n",
    "                  onnx_model_path,     # where to save the model\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  opset_version=17,    # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names=['input'],   # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  dynamic_axes={'input': {0: 'batch_size'},  # variable length axes\n",
    "                                'output': {0: 'batch_size'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpile your model to Orion Cairo\n",
    "\n",
    "We will use the Giza-CLI to transpile our ONNX model to Orion Cairo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m03\u001b[0m \u001b[1;92m16:03:36\u001b[0m.\u001b[1;36m422\u001b[0m\u001b[1m]\u001b[0m No model id provided, checking if model exists âœ…\n",
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m03\u001b[0m \u001b[1;92m16:03:36\u001b[0m.\u001b[1;36m425\u001b[0m\u001b[1m]\u001b[0m Model name is: decision_tree\n",
      "\u001b[2K\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m03\u001b[0m \u001b[1;92m16:04:09\u001b[0m.\u001b[1;36m291\u001b[0m\u001b[1m]\u001b[0m Model already exists, using existing model âœ… \n",
      "\u001b[2K\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m03\u001b[0m \u001b[1;92m16:04:09\u001b[0m.\u001b[1;36m292\u001b[0m\u001b[1m]\u001b[0m Model found with id -> \u001b[1;36m146\u001b[0m! âœ…\n",
      "\u001b[2K\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m03\u001b[0m \u001b[1;92m16:04:09\u001b[0m.\u001b[1;36m951\u001b[0m\u001b[1m]\u001b[0m Version Created with id -> \u001b[1;36m2\u001b[0m! âœ…\n",
      "\u001b[2K\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m03\u001b[0m \u001b[1;92m16:04:09\u001b[0m.\u001b[1;36m952\u001b[0m\u001b[1m]\u001b[0m Sending model for transpilation âœ… \n",
      "\u001b[2K\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m03\u001b[0m \u001b[1;92m16:04:51\u001b[0m.\u001b[1;36m488\u001b[0m\u001b[1m]\u001b[0m Transpilation is fully compatible. Version compiled and Sierra is saved at Giza âœ…\n",
      "\u001b[2K\u001b[32mâ ‡\u001b[0m Transpiling Model...\n",
      "\u001b[1A\u001b[2K\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m03\u001b[0m \u001b[1;92m16:04:52\u001b[0m.\u001b[1;36m201\u001b[0m\u001b[1m]\u001b[0m Downloading model âœ…\n",
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m03\u001b[0m \u001b[1;92m16:04:52\u001b[0m.\u001b[1;36m241\u001b[0m\u001b[1m]\u001b[0m model saved at: verifiable_dt\n"
     ]
    }
   ],
   "source": [
    "! giza transpile decision_tree.onnx --output-path verifiable_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy an inference endpoint\n",
    "\n",
    "Now that our model is transpiled to Cairo we can deploy an endpoint to run verifiable inferences. We will use Giza CLI again to run and deploy an endpoint.\n",
    "Ensure to replace `model-id` and `version-id` with your ids provided during transpilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2Kâ–°â–°â–±â–±â–±â–±â–± Creating endpoint!t!\n",
      "\u001b[?25h\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m03\u001b[0m \u001b[1;92m16:05:20\u001b[0m.\u001b[1;36m152\u001b[0m\u001b[1m]\u001b[0m Endpoint is successful âœ…\n",
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m03\u001b[0m \u001b[1;92m16:05:20\u001b[0m.\u001b[1;36m156\u001b[0m\u001b[1m]\u001b[0m Endpoint created with id -> \u001b[1;36m36\u001b[0m âœ…\n",
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m03\u001b[0m \u001b[1;92m16:05:20\u001b[0m.\u001b[1;36m156\u001b[0m\u001b[1m]\u001b[0m Endpoint created with endpoint URL: \u001b[4;94mhttps://endpoint-raphael-doukhan-146-2-98feddf7-6nn4ryaqca-ew.a.run.app\u001b[0m ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "! giza endpoints deploy --model-id 146 --version-id 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a verifiable inference in AI Agents\n",
    "\n",
    "To streamline a verifiable inference, you might consider using the endpoint URL obtained after transpilation. However, this approach requires manual serialization of the input for the Cairo program and handling the deserialization process. To make this process more user-friendly and keep you within a Python environment, we've introduced giza-agents. A Python package designed to facilitate the creation of ML workflows and execution of verifiable predictions. When you initiate a prediction, our system automatically retrieves the endpoint URL you deployed earlier, converts your input into Cairo-compatible format, executes the prediction, and then converts the output back into a numpy object. More info about [AI Agents here.](https://docs.gizatech.xyz/products/ai-agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run a verifiable inference with AI Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from giza.agents.model import GizaModel\n",
    "\n",
    "MODEL_ID = 146  # Update with your model ID\n",
    "VERSION_ID = 2  # Update with your version ID\n",
    "\n",
    "\n",
    "def prediction(input, model_id, version_id):\n",
    "    model = GizaModel(id=model_id, version=version_id)\n",
    "\n",
    "    (result, proof_id) = model.predict(\n",
    "        input_feed={'input': input}, \n",
    "        verifiable=True,\n",
    "        custom_output_dtype=\"(Tensor<i32>, Tensor<FP16x16>)\" # Decision Tree will always have this output dtype.\n",
    "    )\n",
    "\n",
    "    return result, proof_id\n",
    "\n",
    "\n",
    "def execution():\n",
    "    # The input data type should match the model's expected input\n",
    "    input = input_sample.numpy()\n",
    "\n",
    "    (result, proof_id) = prediction(input, MODEL_ID, VERSION_ID)\n",
    "\n",
    "    return result, proof_id\n",
    "\n",
    "\n",
    "execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the proof\n",
    "\n",
    "Initiating a verifiable inference sets off a proving job on our server, sparing you the complexities of installing and configuring the prover yourself. Upon completion, you can download your proof."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's check the status of the proving job to ensure that it has been completed. \n",
    "\n",
    "ðŸš¨ Remember to substitute `endpoint-id` and `proof-id` with the specific IDs assigned to you throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m19\u001b[0m \u001b[1;92m11:51:45\u001b[0m.\u001b[1;36m470\u001b[0m\u001b[1m]\u001b[0m Getting proof from endpoint \u001b[1;36m109\u001b[0m âœ… \n",
      "\u001b[1m{\u001b[0m\n",
      "  \u001b[1;34m\"id\"\u001b[0m: \u001b[1;36m664\u001b[0m,\n",
      "  \u001b[1;34m\"job_id\"\u001b[0m: \u001b[1;36m831\u001b[0m,\n",
      "  \u001b[1;34m\"metrics\"\u001b[0m: \u001b[1m{\u001b[0m\n",
      "    \u001b[1;34m\"proving_time\"\u001b[0m: \u001b[1;36m15.083126\u001b[0m\n",
      "  \u001b[1m}\u001b[0m,\n",
      "  \u001b[1;34m\"created_date\"\u001b[0m: \u001b[32m\"2024-03-19T10:41:11.120310\"\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! giza endpoints get-proof --endpoint-id 36 --proof-id \"3bb53193c43048b7b47abfefe32b569a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the proof is ready, you can download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m19\u001b[0m \u001b[1;92m11:55:49\u001b[0m.\u001b[1;36m713\u001b[0m\u001b[1m]\u001b[0m Getting proof from endpoint \u001b[1;36m109\u001b[0m âœ… \n",
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m19\u001b[0m \u001b[1;92m11:55:50\u001b[0m.\u001b[1;36m493\u001b[0m\u001b[1m]\u001b[0m Proof downloaded to zklr.proof âœ… \n"
     ]
    }
   ],
   "source": [
    "! giza endpoints download-proof --endpoint-id 36 --proof-id \"3bb53193c43048b7b47abfefe32b569a\" --output-path zkdt.proof"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "giza-agents-mYf3m_Lk-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
